"""
BiRefNet ê¸°ë°˜ ê³ í’ˆì§ˆ ë°°ê²½ ì œê±° ëª¨ë“ˆ
"""

import os
import torch
from PIL import Image
from transformers import AutoModelForImageSegmentation
from torchvision import transforms


class BiRefNetModel:
    """ê³ í’ˆì§ˆ ë°°ê²½ ì œê±° ëª¨ë¸"""
    
    def __init__(self):
        self.model = None
        self.transform = None
        self.device = None
        self.loaded = False
        
    def load_model(self, progress_callback=None):
        """ëª¨ë¸ ë¡œë“œ"""
        if self.loaded:
            return
            
        try:
            if progress_callback:
                progress_callback(10, "ğŸ¤– AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            if torch.backends.mps.is_available():
                self.device = torch.device("mps")
                print("ğŸ Apple Silicon GPU(MPS) ì‚¬ìš©")
            elif torch.cuda.is_available():
                self.device = torch.device("cuda")
                print("ğŸ”¥ NVIDIA GPU ì‚¬ìš©")
            else:
                self.device = torch.device("cpu")
                print("ğŸ’» CPU ì‚¬ìš©")
            
            if progress_callback:
                progress_callback(30, "ğŸ“¥ ê³ í’ˆì§ˆ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # @models/ í´ë”ì—ì„œ BiRefNet ëª¨ë¸ ë¡œë“œ
            models_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'models')
            os.makedirs(models_dir, exist_ok=True)
            
            self.model = AutoModelForImageSegmentation.from_pretrained(
                'zhengpeng7/BiRefNet', 
                trust_remote_code=True,
                cache_dir=models_dir  # @models/ í´ë”ì— ìºì‹œ ì €ì¥
            )
            self.model.to(self.device)
            self.model.eval()
            
            if progress_callback:
                progress_callback(50, "âš™ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì • ì¤‘...")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •
            self.transform = transforms.Compose([
                transforms.Resize((1024, 1024)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            
            if progress_callback:
                progress_callback(70, "ğŸ”§ ëª¨ë¸ ìµœì í™” ì¤‘...")
            
            # ëª¨ë¸ ìµœì í™”
            torch.set_float32_matmul_precision(['high', 'highest'][0])
            
            self.loaded = True
            
            if progress_callback:
                progress_callback(80, "âœ… ê³ í’ˆì§ˆ AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
            
            print("ğŸš€ ê³ í’ˆì§ˆ ë°°ê²½ ì œê±° ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            if progress_callback:
                progress_callback(0, f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def remove_background(self, image, progress_callback=None):
        """ê³ í’ˆì§ˆ ë°°ê²½ ì œê±°"""
        if not self.loaded:
            self.load_model(progress_callback)
        
        try:
            if progress_callback:
                progress_callback(85, "ğŸ¯ AIê°€ ê³ ì •ë°€ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            # ì›ë³¸ í¬ê¸° ì €ì¥
            original_size = image.size
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            if progress_callback:
                progress_callback(90, "ğŸ”® ê³ í’ˆì§ˆ ë°°ê²½ ì œê±° ì²˜ë¦¬ ì¤‘...")
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                preds = self.model(input_tensor)[-1].sigmoid().cpu()
            
            # ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
            pred = preds[0].squeeze()
            pred_pil = transforms.ToPILImage()(pred)
            mask = pred_pil.resize(original_size, Image.Resampling.LANCZOS)
            
            if progress_callback:
                progress_callback(95, "âœ¨ ìµœì¢… ì´ë¯¸ì§€ í•©ì„± ì¤‘...")
            
            # ì›ë³¸ ì´ë¯¸ì§€ì— ë§ˆìŠ¤í¬ ì ìš©
            image_rgba = image.convert("RGBA")
            image_rgba.putalpha(mask)
            
            if progress_callback:
                progress_callback(100, "ğŸ‰ ê³ í’ˆì§ˆ ë°°ê²½ ì œê±° ì™„ë£Œ!")
            
            return image_rgba
            
        except Exception as e:
            print(f"âŒ ë°°ê²½ ì œê±° ì‹¤íŒ¨: {e}")
            if progress_callback:
                progress_callback(0, f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise
